{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Project 5 Vehicle Detection and Tracking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell passed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pachinko/anaconda3/envs/py353/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2, glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pickle\n",
    "from tool_functions import *\n",
    "#%matplotlib qt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import params\n",
    "# ### TODO: Tweak these parameters and see how the results change.\n",
    "# #color_space = 'RGB' # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "# #color_space = 'HSV'\n",
    "# color_space = 'HLS'\n",
    "\n",
    "# orient = 9  # HOG orientations\n",
    "\n",
    "# #pix_per_cell = 8 # HOG pixels per cell\n",
    "# # making it 4 to have more rect in find_cars \n",
    "# pix_per_cell = 4 # HOG pixels per cell\n",
    "\n",
    "# cell_per_block = 2 # HOG cells per block\n",
    "\n",
    "# hog_channel = 'ALL' # Can be 0, 1, 2, or \"ALL\"\n",
    "# #spatial_size = (16, 16) # Spatial binning dimensions\n",
    "# spatial_size = (16, 16) # Spatial binning dimensions\n",
    "\n",
    "# #hist_bins = 16    # Number of histogram bins\n",
    "# hist_bins = 16    # Number of histogram bins\n",
    "\n",
    "# spatial_feat = True # Spatial features on or off\n",
    "# hist_feat = True # Histogram features on or off\n",
    "# hog_feat = True # HOG features on or off\n",
    "# y_start_stop = [None, None] # Min and max in y to search in slide_window()\n",
    "\n",
    "# # global variables:\n",
    "# X_scaler = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import params\n",
    "### TODO: Tweak these parameters and see how the results change.\n",
    "#color_space = 'RGB' # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "#color_space = 'HSV'\n",
    "color_space = params.color_space\n",
    "# HOG orientations\n",
    "orient = params.orient\n",
    "pix_per_cell = params.pix_per_cell     # HOG pixels per cell\n",
    "cell_per_block = params.cell_per_block # HOG cells per block\n",
    "hog_channel = params.hog_channel # Can be 0, 1, 2, or \"ALL\"\n",
    "spatial_size = params.spatial_size # Spatial binning dimensions\n",
    "hist_bins = params.hist_bins    # Number of histogram bins\n",
    "\n",
    "spatial_feat = params.spatial_feat # Spatial features on or off\n",
    "hist_feat = params.hist_feat # Histogram features on or off\n",
    "hog_feat = params.hog_feat # HOG features on or off\n",
    "y_start_stop = params.y_start_stop # Min and max in y to search in slide_window()\n",
    "\n",
    "# global variables:\n",
    "X_scaler = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save/clf.pickle exist! Don't train classifier, just load it.\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "cell passed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pachinko/anaconda3/envs/py353/lib/python3.5/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator LinearSVC from version 0.19.0 when using version 0.18.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/pachinko/anaconda3/envs/py353/lib/python3.5/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator StandardScaler from version 0.19.0 when using version 0.18.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "clf_file = Path(\"save/clf.pickle\")\n",
    "scaler_file = Path(\"save/x_scaler.pickle\")\n",
    "if clf_file.is_file() & scaler_file.is_file():\n",
    "    print(clf_file,  \"exist! Don't train classifier, just load it.\")\n",
    "    with open('save/clf.pickle', 'rb') as f:\n",
    "        clf2 = pickle.load(f)\n",
    "        print(clf2)    \n",
    "    with open('save/x_scaler.pickle', 'rb') as f:\n",
    "        global X_scaler\n",
    "        X_scaler = pickle.load(f)\n",
    "else:\n",
    "    print(\" One or more model files not exist, start training classifier...\")\n",
    "    clf2 = train_classifier()\n",
    "\n",
    "print('cell passed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed_time :  0.40860915184020996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pachinko/anaconda3/envs/py353/lib/python3.5/site-packages/skimage/feature/_hog.py:119: skimage_deprecation: Default value of `block_norm`==`L1` is deprecated and will be changed to `L2-Hys` in v0.15\n",
      "  'be changed to `L2-Hys` in v0.15', skimage_deprecation)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (1,6108) (25116,) (1,6108) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-936e0f263f07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m                         \u001b[0mcell_per_block\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcell_per_block\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                         \u001b[0mhog_channel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhog_channel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                         \u001b[0;34m,\u001b[0m\u001b[0mspatial_feat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspatial_feat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhist_feat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhist_feat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhog_feat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhog_feat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m                             )\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pachinko/codes/carnd/p5/carnd-vehicle-detection-p5/tool_functions.py\u001b[0m in \u001b[0;36msearch_windows\u001b[0;34m(img, windows, clf, scaler, color_space, spatial_size, hist_bins, hist_range, orient, pix_per_cell, cell_per_block, hog_channel, spatial_feat, hist_feat, hog_feat)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;31m#        print('features shape: ',features.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;31m#5) Scale extracted features to be fed to classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0mtest_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0;31m#6) Predict using your classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pachinko/anaconda3/envs/py353/lib/python3.5/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, y, copy)\u001b[0m\n\u001b[1;32m    658\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_mean\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 660\u001b[0;31m                 \u001b[0mX\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    661\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_std\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1,6108) (25116,) (1,6108) "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2, glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pickle\n",
    "from tool_functions import *\n",
    "\n",
    "#%matplotlib qt\n",
    "%matplotlib inline\n",
    "start_time = time.time()\n",
    "\n",
    "image = mpimg.imread('test_images/test6.jpg')\n",
    "draw_image = np.copy(image)\n",
    "\n",
    "# Uncomment the following line if you extracted training\n",
    "# data from .png images (scaled 0 to 1 by mpimg) and the\n",
    "# image you are searching is a .jpg (scaled 0 to 255)\n",
    "image = image.astype(np.float32)/255\n",
    "\n",
    "windows = slide_window(image, x_start_stop=[None, None], y_start_stop=y_start_stop, \n",
    "                    xy_window=(96, 96), xy_overlap=(0.5, 0.5))\n",
    "# windows = slide_window(image, x_start_stop=[None, None], y_start_stop=y_start_stop, \n",
    "#                     xy_window=(48, 48), xy_overlap=(0.5, 0.5))\n",
    "windows = slide_window(image, x_start_stop=[None, None], y_start_stop=y_start_stop, \n",
    "                    xy_window=(64, 64), xy_overlap=(0.5, 0.5))\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print('elapsed_time : ', elapsed_time )\n",
    "\n",
    "hot_windows = search_windows(image, windows, clf2, X_scaler, color_space=color_space, \n",
    "                        spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                        orient=orient, pix_per_cell=pix_per_cell, \n",
    "                        cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel\n",
    "                        ,spatial_feat=spatial_feat, hist_feat=hist_feat, hog_feat=hog_feat\n",
    "                            )\n",
    "\n",
    "window_img = draw_boxes(image, windows, color=(0, 0, 255), thick=6)                    \n",
    "plt.imshow(window_img)\n",
    "plt.show()\n",
    "\n",
    "window_img = draw_boxes(draw_image, hot_windows, color=(0, 0, 255), thick=6)                    \n",
    "plt.imshow(window_img)\n",
    "plt.show()\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print('elapsed_time : ', elapsed_time )\n",
    "\n",
    "print('cell passed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test on findcars.\n",
    "ystart = 400\n",
    "ystop = 656\n",
    "scale = 1.5\n",
    "\n",
    "filenames = glob.glob('test_images/*.jpg')\n",
    "print('images : ', filenames)\n",
    "for filename in filenames:\n",
    "    img = mpimg.imread(filename)\n",
    "    out_img, rect = find_cars(img, ystart, ystop, scale, clf2, X_scaler, orient, \n",
    "                              pix_per_cell, cell_per_block, spatial_size, hist_bins)\n",
    "\n",
    "    plt.imshow(out_img)\n",
    "    plt.show()\n",
    "print('cell passed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# testing on def makeheatmap.\n",
    "filenames = glob.glob('test_images/*.jpg')\n",
    "print('images : ', filenames)\n",
    "for filename in filenames:\n",
    "    img = mpimg.imread(filename)\n",
    "    out_img, rect = find_cars(img, ystart, ystop, scale, clf2, X_scaler, orient, \n",
    "                              pix_per_cell, cell_per_block, spatial_size, hist_bins)\n",
    "\n",
    "    heatmap_threshold = 2\n",
    "    heat_img = makeheatmap(img, rect, heatmap_threshold, True)\n",
    "#     plt.imshow(heat_img)\n",
    "#     plt.show()\n",
    "\n",
    "print('cell passed.')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#interrupt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_one_image(img, debug = False):\n",
    "    out_img, rect = find_cars(img, ystart, ystop, scale, clf2, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins)\n",
    "#     heatmap_threshold = 2\n",
    "    heat_img = makeheatmap(img, rect, heatmap_threshold, debug)\n",
    "    return heat_img\n",
    "\n",
    "def process_image(image, debug = False):\n",
    "    # NOTE: The output you return should be a color image (3 channel) for processing video below\n",
    "    # TODO: put your pipeline here,\n",
    "    # you should return the final output (image where lines are drawn on lanes)\n",
    "    \n",
    "    # turn on debug to produce some image, for debugging or the writeups.\n",
    "    debug = False\n",
    "    debug = True\n",
    "    return process_one_image(image, debug)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make sure the output folder exist.\n",
    "import os\n",
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "outputdir = 'test_videos_output'\n",
    "if not os.path.exists(outputdir):\n",
    "    os.makedirs(outputdir)\n",
    "    \n",
    "white_output = outputdir + '/project-output.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "##clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\").subclip(0,5)\n",
    "clip1 = VideoFileClip(\"project_video.mp4\").subclip(33, 37)\n",
    "#clip1 = VideoFileClip(\"project_video.mp4\").subclip(39,43)\n",
    "#clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "\n",
    "#clip1 = VideoFileClip(\"challenge_video.mp4\")\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "interrupt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make sure the output folder exist.\n",
    "import os\n",
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "outputdir = 'test_videos_output'\n",
    "if not os.path.exists(outputdir):\n",
    "    os.makedirs(outputdir)\n",
    "    \n",
    "white_output = outputdir + '/project-output-full.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "##clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\").subclip(0,5)\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")#.subclip(33, 37)\n",
    "#clip1 = VideoFileClip(\"project_video.mp4\").subclip(39,43)\n",
    "#clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "\n",
    "#clip1 = VideoFileClip(\"challenge_video.mp4\")\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
